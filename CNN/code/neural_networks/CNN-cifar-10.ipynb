{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-01-29T05:38:02.116426Z","iopub.status.busy":"2025-01-29T05:38:02.116100Z","iopub.status.idle":"2025-01-29T05:38:02.420305Z","shell.execute_reply":"2025-01-29T05:38:02.419536Z","shell.execute_reply.started":"2025-01-29T05:38:02.116400Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:02.422695Z","iopub.status.busy":"2025-01-29T05:38:02.422098Z","iopub.status.idle":"2025-01-29T05:38:05.089055Z","shell.execute_reply":"2025-01-29T05:38:05.088106Z","shell.execute_reply.started":"2025-01-29T05:38:02.422662Z"},"trusted":true},"outputs":[],"source":["# Imports for pytorch\n","import numpy as np\n","import torch\n","import torchvision\n","from torch import nn\n","import matplotlib\n","from matplotlib import pyplot as plt\n","import tqdm\n","import copy\n","import torch.utils.data as data\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:05.090745Z","iopub.status.busy":"2025-01-29T05:38:05.090163Z","iopub.status.idle":"2025-01-29T05:38:08.745196Z","shell.execute_reply":"2025-01-29T05:38:08.744488Z","shell.execute_reply.started":"2025-01-29T05:38:05.090720Z"},"trusted":true},"outputs":[],"source":["transform = torchvision.transforms.ToTensor()\n","\n","unprocessed_train_data = torchvision.datasets.CIFAR100(\n","    root=\"data\",\n","    train=True,\n","    download=True\n",")\n","\n","\n","\n","arr_mean = np.mean(unprocessed_train_data.data, axis=(0, 1, 2)) / 255\n","arr_sd = np.std(unprocessed_train_data.data, axis=(0, 1, 2)) / 255\n","\n","SIZE = 112\n","\n","\n","train_transforms = torchvision.transforms.Compose([\n","                           torchvision.transforms.Resize(SIZE),\n","                           torchvision.transforms.RandomRotation(5),\n","                           torchvision.transforms.RandomHorizontalFlip(0.5),\n","                           torchvision.transforms.RandomCrop(SIZE, padding=10),\n","                           torchvision.transforms.ToTensor(),\n","                           torchvision.transforms.Normalize(mean=arr_mean,\n","                                                std=arr_sd)\n","                       ])\n","\n","test_transforms = torchvision.transforms.Compose([\n","                           torchvision.transforms.Resize(SIZE),\n","                           torchvision.transforms.ToTensor(),\n","                           torchvision.transforms.Normalize(mean=arr_mean,\n","                                                std=arr_sd)\n","                           ])\n","training_data = torchvision.datasets.CIFAR10(root = 'data',\n","                              train=True,\n","                              download=True,\n","                              transform=train_transforms)\n","\n","test_data = torchvision.datasets.CIFAR10(root = 'data',\n","                             train=False,\n","                             download=True,\n","                             transform=test_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:08.747220Z","iopub.status.busy":"2025-01-29T05:38:08.746956Z","iopub.status.idle":"2025-01-29T05:38:08.753829Z","shell.execute_reply":"2025-01-29T05:38:08.752971Z","shell.execute_reply.started":"2025-01-29T05:38:08.747199Z"},"trusted":true},"outputs":[],"source":["test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:08.755139Z","iopub.status.busy":"2025-01-29T05:38:08.754875Z","iopub.status.idle":"2025-01-29T05:38:08.767320Z","shell.execute_reply":"2025-01-29T05:38:08.766572Z","shell.execute_reply.started":"2025-01-29T05:38:08.755108Z"},"trusted":true},"outputs":[],"source":["train_data, val_data = data.random_split(training_data,\n","                                           [int(training_data.data.shape[0] * 0.9), int(training_data.data.shape[0] * 0.1)])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:08.768542Z","iopub.status.busy":"2025-01-29T05:38:08.768250Z","iopub.status.idle":"2025-01-29T05:38:08.857250Z","shell.execute_reply":"2025-01-29T05:38:08.856564Z","shell.execute_reply.started":"2025-01-29T05:38:08.768507Z"},"trusted":true},"outputs":[],"source":["val_data = copy.deepcopy(val_data)\n","val_data.dataset.transform = test_transforms #make sure the val data uses test transform"]},{"cell_type":"markdown","metadata":{},"source":["# **Build Model Architecture**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:08.858594Z","iopub.status.busy":"2025-01-29T05:38:08.858259Z","iopub.status.idle":"2025-01-29T05:38:08.865621Z","shell.execute_reply":"2025-01-29T05:38:08.864716Z","shell.execute_reply.started":"2025-01-29T05:38:08.858566Z"},"trusted":true},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self, output_dim):\n","        super().__init__()\n","\n","        self.linear1 = nn.Linear(25088, 256)\n","        #self.linear2 = nn.Linear(512, 256)\n","        self.linear2 = nn.Linear(256, 256)\n","        self.linear3 = nn.Linear(512, 256)\n","        self.linear4 = nn.Linear(512, 256)\n","        #self.linear5 = nn.Linear(512, 256)\n","        #self.linear6 = nn.Linear(1024, 512)\n","        #self.linear7 = nn.Linear(512, 256)\n","        \n","        self.linearOutput = nn.Linear(512, output_dim)\n","\n","        self.dropout = nn.Dropout(0.3)\n","        \n","        self.layer1 = nn.LayerNorm(256)\n","        #self.layer2 = nn.LayerNorm(256)\n","        \n","\n","    def forward(self, x):\n","        \n","        linearOutput1 = self.linear1(x)\n","        x = nn.functional.relu(linearOutput1)\n","        x = self.layer1(x)\n","        x = self.dropout(x)\n","\n","        linearOutput2 = self.linear2(x)\n","        x = nn.functional.relu(linearOutput2)\n","        x = torch.cat([x, linearOutput2], -1)\n","        x = self.dropout(x)\n","\n","        \n","        linearOutput3 = self.linear3(x)\n","        x = nn.functional.relu(linearOutput3)\n","        x = torch.cat([x, linearOutput3], -1)\n","        x = self.dropout(x)\n","\n","        linearOutput4 = self.linear4(x)\n","        x = nn.functional.relu(linearOutput4)\n","        x = torch.cat([x, linearOutput4], -1)\n","        x = self.dropout(x)\n","\n","        x = self.linearOutput(x)\n","        \n","        return x\n","        \n","\n","\n","        \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:08.867069Z","iopub.status.busy":"2025-01-29T05:38:08.866811Z","iopub.status.idle":"2025-01-29T05:38:08.881074Z","shell.execute_reply":"2025-01-29T05:38:08.880217Z","shell.execute_reply.started":"2025-01-29T05:38:08.867050Z"},"trusted":true},"outputs":[],"source":["class VGG(nn.Module):\n","    def __init__(self, features, output_dim):\n","        super().__init__()\n","\n","        self.features = features\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((7,7))\n","\n","        self.classifier = Classifier(output_dim)\n","    \n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        h = x.view(x.shape[0], -1)\n","        x = self.classifier(h)\n","        return x, h\n","\n"," \n","                \n","def design_layers(config, batch_norm):\n","\n","    layers = []\n","    in_channels = 3\n","\n","    for c in config:\n","\n","        if c == 'M':\n","            layers += [nn.MaxPool2d(kernel_size=2, stride = 2)]\n","        else:\n","        \n","            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n","            else:\n","                layers += [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = c\n","\n","    return nn.Sequential(*layers)\n","seq = [512, 512, \"M\", 512, 512, \"M\", 256, 256, \"M\", 64, \"M\"]\n","#[64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"]\n","#[64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n","\n","\n","\n","# reference from https://pytorch.org/vision/0.8/_modules/torchvision/models/vgg.html"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:08.882400Z","iopub.status.busy":"2025-01-29T05:38:08.882110Z","iopub.status.idle":"2025-01-29T05:38:09.016493Z","shell.execute_reply":"2025-01-29T05:38:09.015725Z","shell.execute_reply.started":"2025-01-29T05:38:08.882380Z"},"trusted":true},"outputs":[],"source":["vgg1_layers = design_layers(seq, batch_norm=True)\n","model = VGG(vgg1_layers, 32)\n","vgg1_layers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:09.020505Z","iopub.status.busy":"2025-01-29T05:38:09.020199Z","iopub.status.idle":"2025-01-29T05:38:09.025138Z","shell.execute_reply":"2025-01-29T05:38:09.024241Z","shell.execute_reply.started":"2025-01-29T05:38:09.020484Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 128\n","\n","all_train_iterator = data.DataLoader(training_data,\n","                                 shuffle=True,\n","                                 batch_size=BATCH_SIZE)\n","\n","\n","train_iterator = data.DataLoader(train_data,\n","                                 shuffle=True,\n","                                 batch_size=BATCH_SIZE)\n","\n","val_iterator = data.DataLoader(val_data,\n","                                 batch_size=BATCH_SIZE)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:09.026375Z","iopub.status.busy":"2025-01-29T05:38:09.026144Z","iopub.status.idle":"2025-01-29T05:38:09.036020Z","shell.execute_reply":"2025-01-29T05:38:09.035221Z","shell.execute_reply.started":"2025-01-29T05:38:09.026355Z"},"trusted":true},"outputs":[],"source":["all_train_iterator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:09.037233Z","iopub.status.busy":"2025-01-29T05:38:09.037002Z","iopub.status.idle":"2025-01-29T05:38:09.196273Z","shell.execute_reply":"2025-01-29T05:38:09.195576Z","shell.execute_reply.started":"2025-01-29T05:38:09.037214Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","model = model.to(device)\n","CEL = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:09.197968Z","iopub.status.busy":"2025-01-29T05:38:09.197343Z","iopub.status.idle":"2025-01-29T05:38:09.203545Z","shell.execute_reply":"2025-01-29T05:38:09.202744Z","shell.execute_reply.started":"2025-01-29T05:38:09.197935Z"},"trusted":true},"outputs":[],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:09.204981Z","iopub.status.busy":"2025-01-29T05:38:09.204665Z","iopub.status.idle":"2025-01-29T05:38:09.214576Z","shell.execute_reply":"2025-01-29T05:38:09.213785Z","shell.execute_reply.started":"2025-01-29T05:38:09.204954Z"},"trusted":true},"outputs":[],"source":["import torch.optim as optim\n","\n","\n","params = [\n","          {'params': model.features.parameters()}, #, 'lr': 5e-4 / 10},\n","          {'params': model.classifier.parameters()}\n","         ]\n","\n","optimizer = optim.AdamW(params, lr=5e-3, weight_decay = 1e-4)\n","from tqdm.notebook import trange, tqdm\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:09.215913Z","iopub.status.busy":"2025-01-29T05:38:09.215606Z","iopub.status.idle":"2025-01-29T05:38:09.229745Z","shell.execute_reply":"2025-01-29T05:38:09.228976Z","shell.execute_reply.started":"2025-01-29T05:38:09.215887Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import trange, tqdm\n","\n","def train(model, iterator, optimizer, CEL, device):\n","\n","    epoch_loss = 0\n","    epoch_accuracy = 0\n","\n","    model.train()\n","\n","    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n","\n","        x = x.to(device)\n","        y = y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        y_pred, _ = model(x)\n","\n","        loss = CEL(y_pred, y)\n","\n","        accuracy = calculate_accuracy(y_pred, y)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_accuracy += accuracy.item()\n","\n","    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)\n","\n","\n","def evaluate(model, iterator, CEL, device):\n","\n","    epoch_loss = 0\n","    epoch_accuracy = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n","\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            y_pred, _ = model(x)\n","\n","            loss = CEL(y_pred, y)\n","\n","            accuracy = calculate_accuracy(y_pred, y)\n","\n","            epoch_loss += loss.item()\n","            epoch_accuracy += accuracy.item()\n","\n","    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)\n","\n","def calculate_accuracy(y_pred, y):\n","    first_pred = y_pred.argmax(1, keepdim=True)\n","    correct = first_pred.eq(y.view_as(first_pred)).sum()\n","    accuracy = correct.float() / y.shape[0]\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-29T05:38:09.230956Z","iopub.status.busy":"2025-01-29T05:38:09.230673Z","iopub.status.idle":"2025-01-29T05:38:10.746225Z","shell.execute_reply":"2025-01-29T05:38:10.744877Z","shell.execute_reply.started":"2025-01-29T05:38:09.230898Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 20\n","\n","best_val_loss = float('inf')\n","\n","train_accuracies = []\n","val_accuracies = []\n","train_losses = []\n","val_losses = []\n","\n","for epoch in trange(EPOCHS):\n","\n","    train_loss, train_accuracy = train(model, train_iterator, optimizer, CEL, device)\n","    val_loss, val_accuracy = evaluate(model, val_iterator, CEL, device)\n","\n","    train_accuracies.append(train_accuracy)\n","    val_accuracies.append(val_accuracy)\n","    train_losses.append(train_loss)\n","    val_losses.append(val_loss)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_accuracy*100:.2f}%')\n","    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_accuracy*100:.2f}%')\n","\n","\n","plt.plot(range(1, EPOCHS + 1), train_accuracies, label='Train Accuracy')\n","plt.plot(range(1, EPOCHS + 1), val_accuracies, label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Train/Validation Accuracy')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, EPOCHS + 1), train_losses, label='Train Loss')\n","plt.plot(range(1, EPOCHS + 1), val_losses, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Train/Validation Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-01-29T05:38:10.747211Z","iopub.status.idle":"2025-01-29T05:38:10.747587Z","shell.execute_reply":"2025-01-29T05:38:10.747394Z","shell.execute_reply.started":"2025-01-29T05:38:10.747379Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","import os\n","\n","class CIFAR10Test(torchvision.datasets.VisionDataset):\n","\n","    def __init__(self, transform=None, target_transform=None):\n","        super(CIFAR10Test, self).__init__(None, transform=transform,\n","                                      target_transform=target_transform)\n","        assert os.path.exists(\"/kaggle/input/cifar10-test-data-sp24-npy/cifar10_test_data_sp24.npy\"), \"You must upload the test data to the file system.\"\n","        self.data = [np.load(\"/kaggle/input/cifar10-test-data-sp24-npy/cifar10_test_data_sp24.npy\", allow_pickle=False)]\n","\n","        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n","        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n","\n","    def __getitem__(self, index: int):\n","        img = self.data[index]\n","        img = Image.fromarray(img)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img\n","\n","    def __len__(self) -> int:\n","        return len(self.data)\n","\n","# Create the test dataset\n","testing_data = CIFAR10Test(\n","    transform=test_transforms # NOTE: Make sure transform is the same as used in the training dataset.\n",")\n","\n","test_data = torchvision.datasets.CIFAR10(root = 'data',\n","                             train=False,\n","                             download=True,\n","                             transform=test_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-01-29T05:38:10.748848Z","iopub.status.idle":"2025-01-29T05:38:10.749117Z","shell.execute_reply":"2025-01-29T05:38:10.749001Z","shell.execute_reply.started":"2025-01-29T05:38:10.748990Z"},"trusted":true},"outputs":[],"source":["test_iterator = data.DataLoader(testing_data,\n","                                batch_size=BATCH_SIZE,\n","                               shuffle = False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-01-29T05:38:10.750622Z","iopub.status.idle":"2025-01-29T05:38:10.751049Z","shell.execute_reply":"2025-01-29T05:38:10.750833Z","shell.execute_reply.started":"2025-01-29T05:38:10.750815Z"},"trusted":true},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-01-29T05:38:10.752753Z","iopub.status.idle":"2025-01-29T05:38:10.753173Z","shell.execute_reply":"2025-01-29T05:38:10.752974Z","shell.execute_reply.started":"2025-01-29T05:38:10.752958Z"},"trusted":true},"outputs":[],"source":["\n","\n","def get_predictions(model, iterator):\n","\n","    model.eval()\n","    model = model.to(device)\n","    labels = []\n","\n","    with torch.no_grad():\n","        for x in tqdm(iterator):\n","            x = x.to(device)\n","\n","            y_pred, _ = model(x)\n","            \n","            _, predicted_labels = torch.max(y_pred, 1)\n","            \n","            labels.extend(predicted_labels.tolist())\n","    \n","\n","    return labels\n","\n","\n","predictions = get_predictions(model, test_iterator)\n","len(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-01-29T05:38:10.754824Z","iopub.status.idle":"2025-01-29T05:38:10.755242Z","shell.execute_reply":"2025-01-29T05:38:10.755044Z","shell.execute_reply.started":"2025-01-29T05:38:10.755027Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","if isinstance(predictions, np.ndarray):\n","    predictions = predictions.astype(int)\n","else:\n","    predictions = np.array(predictions, dtype=int)\n","assert predictions.shape == (len(testing_data),), \"Predictions were not the correct shape\"\n","df = pd.DataFrame({'Category': predictions})\n","df.index += 1  # Ensures that the index starts at 1.\n","df.to_csv('submission.csv', index_label='Id')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-01-29T05:38:10.756830Z","iopub.status.idle":"2025-01-29T05:38:10.757248Z","shell.execute_reply":"2025-01-29T05:38:10.757054Z","shell.execute_reply.started":"2025-01-29T05:38:10.757036Z"},"trusted":true},"outputs":[],"source":["def unpickle(file):\n","    import pickle\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","unpickle()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4837039,"sourceId":8172589,"sourceType":"datasetVersion"},{"datasetId":6553089,"sourceId":10588448,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
